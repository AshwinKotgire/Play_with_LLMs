## Using Docker to containerize an LLM for simple Q/A

## FastAPI

Using fast api to manage requests
Inintially only response to prompts is given
Later facility to train your own LLM is going to be provided along with function to upload the trained model to huggingface

## To run
```bash
bash run.sh
```